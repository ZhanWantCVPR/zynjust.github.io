---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I received my Master of Engineering in Software Engineering from Nanjing University of Information Science and Technology in 2021, where I specialized in computer vision and video object segmentation. In September 2021, I began my Ph.D. in Control Science and Engineering at Nanjing University of Science and Technology. My research focuses on model efficiency and visual object tracking.


# ğŸ”¥ News
- *Oct 22, 2025*: &nbsp;ğŸ‰ğŸ‰ a paper was reviewed by **ICRA2026**!
- *Sep 28, 2025*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **KBS**!
- *March 3, 2025*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **JVCIR**!
- *October 1, 2024*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **MS**!
- *August 20, 2024*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **IEEE iThings(2024)**!
- *August 19, 2024*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **IEEE iThings(2024)**! 
- *July 17, 2024*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **IEEE CYBER(2024)**!
- *March 17, 2020*: &nbsp;ğŸ‰ğŸ‰ a paper was accepted by **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥**! 

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Multimedia Systems</div><img src='images/MS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SiamRCSC: Robust siamese network with channel and spatial constraints for visual object tracking]([https://link.springer.com/article/10.1007/s00530-024-01524-4](https://link.springer.com/article/10.1007/s00530-024-01524-4))

**Yu Zheng**, Yong Liu, Xun Che

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: Zheng, Y., Liu, Y. & Che, X. SiamRCSC: Robust siamese network with channel and spatial constraints for visual object tracking. Multimedia Systems 30, 323 (2024). https://doi.org/10.1007/s00530-024-01524-4 **(JCR Q1, IF=3.5, CCF Cç±»)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JVCI</div><img src='images/JVCI.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A robust and adaptive framework with spaceâ€“time memory networks for Visual Object Tracking]([https://www.sciencedirect.com/science/article/abs/pii/S1047320325000458](https://www.sciencedirect.com/science/article/abs/pii/S1047320325000458))

**Yu Zheng**, Yong Liu, Xun Che

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: Yu Zheng, Yong Liu, Xun Che, A robust and adaptive framework with spaceâ€“time memory networks for Visual Object Tracking, Journal of Visual Communication and Image Representation, Volume 108, 2025, 104431, ISSN 1047-3203, https://doi.org/10.1016/j.jvcir.2025.104431. **(JCR Q2, IF=2.6, CCF Cç±», é«˜è´¨é‡æœŸåˆŠBç±»)**
 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE CYBER 2024</div><img src='images/CYBER.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RASTMTrack: Robust and Adaptive Space-Time Memory Networks for Visual Tracking]([https://ieeexplore.ieee.org/document/10749627](https://ieeexplore.ieee.org/document/10749627))

**Yu Zheng**, Yong Liu, Xun Che

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: Y. Zheng, Y. Liu and X. Che, "RASTMTrack: Robust and Adaptive Space-Time Memory Networks for Visual Tracking," 2024 IEEE 14th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER), Copenhagen, Denmark, 2024, pp. 314-319, doi: 10.1109/CYBER63482.2024.10749627. **(EI)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE iThings 2024</div><img src='images/Ithings1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Domain-Adaptive Large Language Model With Refinement Framework For IoT Cybersecurity]([https://ieeexplore.ieee.org/abstract/document/10731743](https://ieeexplore.ieee.org/abstract/document/10731743))

Xun Che, **Yu Zheng**, Minhao Zhu, Qianmu Li, Xu Dong

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: X. Che, Y. Zheng, M. Zhu, Q. Li and X. Dong, "A Domain-Adaptive Large Language Model With Refinement Framework For IoT Cybersecurity," 2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics, Copenhagen, Denmark, 2024, pp. 224-229, doi: 10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics62450.2024.00056. **(EI)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE iThings 2024</div><img src='images/Ithings2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Novel Diversified API Recommendation for Power System Sensors]([https://ieeexplore.ieee.org/abstract/document/10731780](https://ieeexplore.ieee.org/abstract/document/10731780))

Minhao Zhu, Huanhuan Gu, Xun Che, Jingfei Chen, Qian Zhao, Fan Liu, **Yu Zheng**

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: M. Zhu et al., "A Novel Diversified API Recommendation for Power System Sensors," 2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics, Copenhagen, Denmark, 2024, pp. 17-22, doi: 10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics62450.2024.00027. **(EI)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JIG</div><img src='images/JIG.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Video object segmentation algorithm based on consistent features]([https://www.cjig.cn/thesisDetails#10.11834/jig.190571&lang=zh](https://www.cjig.cn/thesisDetails#10.11834/jig.190571&lang=zh))

**Yu Zheng**, Yadang Chen, Chuanyan Hao

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: Yu Zheng, Yadang Chen, Chuanyan Hao. Video object segmentation algorithm based on consistent features[J]. Journal of image and graphics, 2020, 25(8): 1558-1566. DOIï¼š 10.11834/jig.190571. **(åŒ—æ ¸, CSCDæ ¸å¿ƒ, EBSCO, Scopus, JST, SWJTU A, SWUFE B, IF=2.428)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Patent</div><img src='images/patent1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ä¸€ç§åŸºäºé«˜é˜¶èƒ½é‡çº¦æŸçš„è§†é¢‘å¯¹è±¡åˆ†å‰²ç®—æ³•]([https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASE0NOMjAxOTEwNjQ5MzUxLjhfc3EaCHgxZW50ZTVz](https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASE0NOMjAxOTEwNjQ5MzUxLjhfc3EaCHgxZW50ZTVz))

é™ˆäºšå½“, **å¾ç…œ**, é‡‘å­é¾™

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: å—äº¬ä¿¡æ¯å·¥ç¨‹å¤§å­¦. ä¸€ç§åŸºäºé«˜é˜¶èƒ½é‡çº¦æŸçš„è§†é¢‘å¯¹è±¡åˆ†å‰²ç®—æ³•:CN201910649351.8[P]. 2023-04-25. **(å‘æ˜ä¸“åˆ©)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Patent</div><img src='images/patent7.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±å’Œå¢é‡å­¦ä¹ çš„ç½‘ç»œå®‰å…¨äº‹ä»¶æ£€æµ‹æ–¹æ³•]([https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyMzEwMjc5MzIxLjkaCHgxZW50ZTVz](https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyMzEwMjc5MzIxLjkaCHgxZW50ZTVz))

è½¦æ´µ, æåƒç›®, æœ±æ—»æ˜Š, åˆ˜å¸†, é™ˆç«é£, èµµè°¦, æå°è¶…, **å¾ç…œ**

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: å—äº¬ç†å·¥å¤§å­¦. ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±å’Œå¢é‡å­¦ä¹ çš„ç½‘ç»œå®‰å…¨äº‹ä»¶æ£€æµ‹æ–¹æ³•:CN202310279321.9[P]. 2025-08-26. **(å‘æ˜ä¸“åˆ©)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Patent</div><img src='images/patent8.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ä¸€ç§åŸºäºæ–‡æœ¬ç”Ÿæˆç½‘ç»œå®‰å…¨åº”æ€¥å“åº”çŸ¥è¯†å›¾è°±æ–¹æ³•]([https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyMzEwMzE2MzA1LjIaCHgxZW50ZTVz](https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyMzEwMzE2MzA1LjIaCHgxZW50ZTVz))

è½¦æ´µ, æåƒç›®, æœ±æ—»æ˜Š, é™ˆç«é£, èµµè°¦, åˆ˜å¸†, **å¾ç…œ**

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: å—äº¬ç†å·¥å¤§å­¦. ä¸€ç§åŸºäºæ–‡æœ¬ç”Ÿæˆç½‘ç»œå®‰å…¨åº”æ€¥å“åº”çŸ¥è¯†å›¾è°±æ–¹æ³•:CN202310316305.2[P]. 2025-09-02. **(å‘æ˜ä¸“åˆ©)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Patent</div><img src='images/patent4.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„å®‰å…¨æµ‹è¯•æç¤ºç”Ÿæˆæ–¹æ³•]([https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyNDEwNDI1MjQ4LjYaCHgxZW50ZTVz](https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyNDEwNDI1MjQ4LjYaCHgxZW50ZTVz))

é™ˆäºšå½“, è½¦æ´µ, æœ±æ—»æ˜Š, å¾ç¿, **å¾ç…œ**, èµµè°¦, åˆ˜å¸†, é™ˆç«é£, é¡¾æ¬¢æ¬¢, èƒ¡å©•, å¯‡æ€€æŒ¯, ç‹åšæ´‹, å¼ å˜‰é“ 

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: æ±Ÿè‹ç‘æ™ºæ ¸ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸. ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„å®‰å…¨æµ‹è¯•æç¤ºç”Ÿæˆæ–¹æ³•:CN202410425248.6[P]. 2024-07-12. **(å‘æ˜ä¸“åˆ©)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Patent</div><img src='images/patent5.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ä¸€ç§åŸºäºä¼˜åŒ–è¯åµŒå…¥çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•]([https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyNDEwNDM3MDA5LjIaCHgxZW50ZTVz](https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyNDEwNDM3MDA5LjIaCHgxZW50ZTVz))

é™ˆäºšå½“, è½¦æ´µ, æœ±æ—»æ˜Š, å¾ç¿, **å¾ç…œ**, èµµè°¦, åˆ˜å¸†, é™ˆç«é£, é¡¾æ¬¢æ¬¢, èƒ¡å©•, å¯‡æ€€æŒ¯, ç‹åšæ´‹, å¼ å˜‰é“ 

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: æ±Ÿè‹ç‘æ™ºæ ¸ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸. ä¸€ç§åŸºäºä¼˜åŒ–è¯åµŒå…¥çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•:CN202410437009.2[P]. 2024-07-12. **(å‘æ˜ä¸“åˆ©)**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Patent</div><img src='images/patent6.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[å¤šé‡ä¿¡æ¯è½´å‘å¼•å¯¼éå¯¹ç§°åŠç›‘ç£è¯­ä¹‰åˆ†å‰²æ–¹æ³•]([https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyNDEwNjIwMjk0LjEaCHgxZW50ZTVz](https://d.wanfangdata.com.cn/patent/ChhQYXRlbnROZXdTMjAyNTAzMTgwODIxNTASEENOMjAyNDEwNjIwMjk0LjEaCHgxZW50ZTVz))

è½¦æ´µ, é™ˆäºšå½“, æœ±æ—»æ˜Š, èµµè°¦, å¾ç¿, é¡¾æ¬¢æ¬¢, **å¾ç…œ**, ç‹ç‰é¹, æœ±è´¤è±ª 

[**Project**]([https://github.com/ZhanWantCVPR](https://github.com/ZhanWantCVPR)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- It will be made public. 
</div>
</div>

- Ref: æ±Ÿè‹ç‘æ™ºæ ¸ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸. å¤šé‡ä¿¡æ¯è½´å‘å¼•å¯¼éå¯¹ç§°åŠç›‘ç£è¯­ä¹‰åˆ†å‰²æ–¹æ³•:CN202410620294.1[P]. 2024-08-09. **(å‘æ˜ä¸“åˆ©)**

# ğŸ– Honors and Awards
- *2024.11* Graduate Study Scholarship (ä¸‰ç­‰).
- *2023.11* Graduate Study Scholarship (ä¸‰ç­‰).
- *2022.11* Graduate Study Scholarship (ä¸‰ç­‰).
- *2021.11* Graduate Study Scholarship (äºŒç­‰). 
- *2020.11* Graduate Study Scholarship (ä¸‰ç­‰). 
- *2019.11* Graduate Study Scholarship (ä¸‰ç­‰). 
- *2018.11* Graduate Study Scholarship (äºŒç­‰). 
- *2016.09* China Software Cup National Third Prize (å¤šæ¨¡æ€èº«ä»½è¯†åˆ«, å…¨å›½ä¸‰ç­‰å¥–). 

# ğŸ“– Educations
- *2021.06 - 2025 (now)*, Nanjing University of Science and Technology (NJUST), Key Laboratory of the Ministry of Education of the People's Republic of China for â€œIntelligent Perception and System of High-Dimensional Informationâ€ (â€œé«˜ç»´ä¿¡æ¯æ™ºèƒ½æ„ŸçŸ¥ä¸ç³»ç»Ÿâ€æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤) â€œNational Key Laboratory of Intelligent Manufacturing of High-end Construction Machinery (â€œé«˜ç«¯å·¥ç¨‹æœºæ¢°æ™ºèƒ½åˆ¶é€ â€å…¨å›½é‡ç‚¹å®éªŒå®¤). PhD degree in Engineering Candidate (å·¥å­¦åšå£«å­¦ä½å€™é€‰äºº). 
- *2018.09 - 2021.06*, Nanjing University of Information Science and Technology (NUIST), Jiangsu Provincial Public Security Bureau Digital Forensics Key Laboratory (æ±Ÿè‹çœå…¬å®‰å…æ•°å­—å–è¯é‡ç‚¹å®éªŒå®¤). Master of Engineering (M.Eng.) degree (å·¥å­¦ç¡•å£«å­¦ä½). 

# ğŸ’¬ Invited Talks
- *August 19, 2024*, A Domain-Adaptive Large Language Model With Refinement Framework For IoT Cybersecurity. 2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics.
- *August 20, 2024*, A Novel Diversified API Recommendation for Power System Sensors. 2024 IEEE International Conferences on Internet of Things (iThings) and IEEE Green Computing & Communications (GreenCom) and IEEE Cyber, Physical & Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics.
- *July 17, 2024*, RASTMTrack: Robust and Adaptive Space-Time Memory Networks for Visual Tracking. 2024 IEEE 14th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER).

# ğŸ’» Internships
- *2021.09 - 2025 (now)*, Yong Liu ([http://gsmis.njust.edu.cn/open/TutorInfo.aspx?dsbh=vGMDvG9Fli2Mw864t7hFyg==&yxsh=z70ppxVSQAs=&zydm=SwsWR9zpmmw=](http://gsmis.njust.edu.cn/open/TutorInfo.aspx?dsbh=vGMDvG9Fli2Mw864t7hFyg==&yxsh=z70ppxVSQAs=&zydm=SwsWR9zpmmw=)), æ±Ÿè‹çœâ€œå…­å¤§äººæ‰é«˜å³°â€Bç±», æ±Ÿè‹çœâ€œé’è“å·¥ç¨‹â€ä¸­é’å¹´å­¦æœ¯å¸¦å¤´äºº, PhD supervisor, China.
- *2018.09 - 2021.06*, Yadang Chen (https://faculty.nuist.edu.cn/chenyadang/zh_CN/index.htm), Master's supervisor, China.
- *2018.09 - 2021.06*, Zhaoqing Pan ([https://seea.tju.edu.cn/info/1015/2556.htm](https://seea.tju.edu.cn/info/1015/2556.htm)), å…¨çƒå‰2%é¡¶å°–ç§‘å­¦å®¶ï¼ˆWorld Top 2% Scientistsï¼‰, Master's supervisor, China.
